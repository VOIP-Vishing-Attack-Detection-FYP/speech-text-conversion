{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: torch in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: future in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (1.3.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (0.57.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from numba>=0.51.0->librosa) (0.40.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from pooch>=1.1->librosa) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python librosa torch torchaudio transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Title: MP3 to Text using Wav2Vec2 (with separate MP3→WAV conversion)\n",
    "\n",
    "# %%\n",
    "# 1. Install Dependencies (Uncomment and run if needed)\n",
    "\n",
    "import os\n",
    "import ffmpeg\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2ForCTC\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 2. Separate Function to Convert MP3 → WAV\n",
    "def convert_mp3_to_wav(mp3_path, wav_path):\n",
    "    \"\"\"\n",
    "    Converts an MP3 file to a single-channel (mono) WAV at 16 kHz \n",
    "    using ffmpeg.\n",
    "    \"\"\"\n",
    "    (\n",
    "        ffmpeg\n",
    "        .input(mp3_path)\n",
    "        .output(\n",
    "            wav_path,\n",
    "            format='wav',       # output format\n",
    "            acodec='pcm_s16le', # audio codec\n",
    "            ac=1,               # number of channels\n",
    "            ar='16000'          # audio sampling rate\n",
    "        )\n",
    "        .run(overwrite_output=True)\n",
    "    )\n",
    "    return wav_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2GroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2Encoder(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2SdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (lm_head): Linear(in_features=1024, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# 3. Load Wav2Vec2 Model & Processor\n",
    "#    We'll use the facebook/wav2vec2-large-960h checkpoint\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 4. Speech-to-Text Function\n",
    "def speech_to_text(audio_path):\n",
    "    \"\"\"\n",
    "    Loads a WAV audio file at 16 kHz using librosa,\n",
    "    then transcribes it using a Wav2Vec2 model.\n",
    "    \"\"\"\n",
    "    # 1. Load the audio with librosa\n",
    "    speech_array, sampling_rate = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "    # 2. Tokenize/preprocess with the processor\n",
    "    inputs = processor(\n",
    "        speech_array,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_values = inputs.input_values.to(device)\n",
    "\n",
    "    # 3. Inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # 4. Decode predicted tokens\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)[0]\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting MP3 to WAV: C:/Users/DELL/Desktop/VOIP_Phishing_Attacks/Repos/SpeechText/speech-text-conversion/assets/sample1.wav → C:/Users/DELL/Desktop/VOIP_Phishing_Attacks/Repos/SpeechText/speech-text-conversion/assets/sample1.wav\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(mp3_file):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Converting MP3 to WAV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmp3_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwav_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mconvert_mp3_to_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp3_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Transcribing the WAV file...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     transcription \u001b[38;5;241m=\u001b[39m speech_to_text(wav_file)\n",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m, in \u001b[0;36mconvert_mp3_to_wav\u001b[1;34m(mp3_path, wav_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_mp3_to_wav\u001b[39m(mp3_path, wav_path):\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    Converts an MP3 file to a single-channel (mono) WAV at 16 kHz \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    using ffmpeg.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     (\n\u001b[1;32m----> 9\u001b[0m         \u001b[43mffmpeg\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp3_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# output format\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43macodec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpcm_s16le\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# audio codec\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# number of channels\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m16000\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# audio sampling rate\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverwrite_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wav_path\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\ffmpeg\\_run.py:313\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(stream_spec, cmd, capture_stdout, capture_stderr, input, quiet, overwrite_output)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;129m@output_operator\u001b[39m()\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[0;32m    291\u001b[0m     stream_spec,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m     overwrite_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    298\u001b[0m ):\n\u001b[0;32m    299\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Invoke ffmpeg for the supplied node graph.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m    Returns: (out, err) tuple containing captured stdout and stderr data.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m     process \u001b[38;5;241m=\u001b[39m \u001b[43mrun_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipe_stdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipe_stdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_stdout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipe_stderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_stderr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     out, err \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    323\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\ffmpeg\\_run.py:284\u001b[0m, in \u001b[0;36mrun_async\u001b[1;34m(stream_spec, cmd, pipe_stdin, pipe_stdout, pipe_stderr, quiet, overwrite_output)\u001b[0m\n\u001b[0;32m    282\u001b[0m stdout_stream \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE \u001b[38;5;28;01mif\u001b[39;00m pipe_stdout \u001b[38;5;129;01mor\u001b[39;00m quiet \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    283\u001b[0m stderr_stream \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE \u001b[38;5;28;01mif\u001b[39;00m pipe_stderr \u001b[38;5;129;01mor\u001b[39;00m quiet \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdin_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdout_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstderr_stream\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\subprocess.py:1436\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1436\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1438\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1452\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1453\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 5. Demo Usage: Converting an MP3 file to WAV, then Transcribing\n",
    "if __name__ == \"__main__\":\n",
    "    # Provide the MP3 file path\n",
    "    mp3_file = \"C:/Users/DELL/Desktop/VOIP_Phishing_Attacks/Repos/SpeechText/speech-text-conversion/assets/sample1.wav\"        # Update with your file\n",
    "    wav_file = \"C:/Users/DELL/Desktop/VOIP_Phishing_Attacks/Repos/SpeechText/speech-text-conversion/assets/sample1.wav\"\n",
    "\n",
    "    if os.path.exists(mp3_file):\n",
    "        print(f\"[INFO] Converting MP3 to WAV: {mp3_file} → {wav_file}\")\n",
    "        convert_mp3_to_wav(mp3_file, wav_file)\n",
    "        \n",
    "        print(\"[INFO] Transcribing the WAV file...\")\n",
    "        transcription = speech_to_text(wav_file)\n",
    "        print(\"\\n[RESULT] Transcription:\")\n",
    "        print(transcription)\n",
    "        \n",
    "        # (Optional) remove the WAV if you no longer need it\n",
    "        # os.remove(wav_file)\n",
    "    else:\n",
    "        print(f\"[WARNING] MP3 file not found: {mp3_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Transcribing: C:\\Users\\DELL\\Desktop\\VOIP_Phishing_Attacks\\Repos\\SpeechText\\speech-text-conversion\\assets\\AudioData\\JK\\a01.wav\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numba' has no attribute 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscriptions.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Perform batch transcription\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[43mbatch_transcribe_wav_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 49\u001b[0m, in \u001b[0;36mbatch_transcribe_wav_files\u001b[1;34m(input_folder, output_file)\u001b[0m\n\u001b[0;32m     46\u001b[0m             wav_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, file_name)\n\u001b[0;32m     47\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Transcribing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwav_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m             transcript \u001b[38;5;241m=\u001b[39m \u001b[43mspeech_to_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranscript\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[INFO] Finished transcribing all WAV files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 22\u001b[0m, in \u001b[0;36mspeech_to_text\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mLoads a WAV file at 16 kHz using librosa,\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mthen transcribes it using the Wav2Vec2 model.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Load audio at 16 kHz\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m speech_array, sampling_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(audio_path, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Preprocess audio\u001b[39;00m\n\u001b[0;32m     25\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(speech_array, sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\lazy_loader\\__init__.py:83\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     81\u001b[0m submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m submod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(submod_path)\n\u001b[1;32m---> 83\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m attr_to_modules[name]:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\lazy_loader\\__init__.py:82\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[0;32m     81\u001b[0m     submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 82\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\librosa\\core\\audio.py:1142\u001b[0m\n\u001b[0;32m   1136\u001b[0m         bwd_pred_error \u001b[38;5;241m=\u001b[39m bwd_pred_error[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ar_coeffs\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;129;43m@stencil\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m-> 1142\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m_zc_stencil\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_pos\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Stencil to compute zero crossings\"\"\"\u001b[39;49;00m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\stencils\\stencil.py:816\u001b[0m, in \u001b[0;36mstencil\u001b[1;34m(func_or_mode, **options)\u001b[0m\n\u001b[0;32m    814\u001b[0m wrapper \u001b[38;5;241m=\u001b[39m _stencil(mode, options)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\stencils\\stencil.py:826\u001b[0m, in \u001b[0;36m_stencil.<locals>.decorated\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compiler\n\u001b[0;32m    825\u001b[0m kernel_ir \u001b[38;5;241m=\u001b[39m compiler\u001b[38;5;241m.\u001b[39mrun_frontend(func)\n\u001b[1;32m--> 826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStencilFunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel_ir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\stencils\\stencil.py:83\u001b[0m, in \u001b[0;36mStencilFunc.__init__\u001b[1;34m(self, kernel_ir, mode, options)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_typingctx \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mcpu_target\u001b[38;5;241m.\u001b[39mtyping_context\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_targetctx \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mcpu_target\u001b[38;5;241m.\u001b[39mtarget_context\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_typingctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_targetctx\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_install_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_typingctx)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\core\\typing\\context.py:160\u001b[0m, in \u001b[0;36mBaseContext.refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_additional_registries()\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Some extensions may have augmented the builtin registry\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_builtins\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\core\\typing\\context.py:421\u001b[0m, in \u001b[0;36mBaseContext._load_builtins\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ctypes_utils, bufproto           \u001b[38;5;66;03m# noqa: F401, E501\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munsafe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eh                    \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstall_registry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuiltin_registry\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\core\\typing\\context.py:441\u001b[0m, in \u001b[0;36mBaseContext.install_registry\u001b[1;34m(self, registry)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsert_function(ftcls(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ftcls \u001b[38;5;129;01min\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mnew_registrations(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsert_attributes(\u001b[43mftcls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gv, gty \u001b[38;5;129;01min\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mnew_registrations(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobals\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    443\u001b[0m     existing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lookup_global(gv)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\core\\typing\\templates.py:1047\u001b[0m, in \u001b[0;36m_OverloadAttributeTemplate.__init__\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28msuper\u001b[39m(_OverloadAttributeTemplate, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(context)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext \u001b[38;5;241m=\u001b[39m context\n\u001b[1;32m-> 1047\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\core\\typing\\templates.py:1097\u001b[0m, in \u001b[0;36m_OverloadMethodTemplate._init_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1094\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attr\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1097\u001b[0m     registry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_target_registry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InternalTargetMismatchError:\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# Target mismatch. Do not register attribute lookup here.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\core\\typing\\templates.py:940\u001b[0m, in \u001b[0;36m_TemplateTargetHelperMixin._get_target_registry\u001b[1;34m(self, reason)\u001b[0m\n\u001b[0;32m    917\u001b[0m tgtctx \u001b[38;5;241m=\u001b[39m disp\u001b[38;5;241m.\u001b[39mtargetdescr\u001b[38;5;241m.\u001b[39mtarget_context\n\u001b[0;32m    918\u001b[0m \u001b[38;5;66;03m# This is all workarounds...\u001b[39;00m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;66;03m# The issue is that whilst targets shouldn't care about which registry\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;66;03m# in which to register lowering implementations, the CUDA target\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;66;03m# In case the target has swapped, e.g. cuda borrowing cpu, refresh to\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;66;03m# populate.\u001b[39;00m\n\u001b[1;32m--> 940\u001b[0m \u001b[43mtgtctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builtin_registry \u001b[38;5;129;01min\u001b[39;00m tgtctx\u001b[38;5;241m.\u001b[39m_registries:\n\u001b[0;32m    942\u001b[0m     reg \u001b[38;5;241m=\u001b[39m builtin_registry\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\core\\base.py:267\u001b[0m, in \u001b[0;36mBaseContext.refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03mRefresh context with new declarations from known registries.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03mUseful for third-party extensions.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# load target specific registries\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_additional_registries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Populate the builtin registry, this has to happen after loading\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;66;03m# additional registries as some of the \"additional\" registries write\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# their implementations into the builtin_registry and would be missed if\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# this ran first.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstall_registry(builtin_registry)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\numba\\core\\cpu.py:99\u001b[0m, in \u001b[0;36mCPUContext.load_additional_registries\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstall_registry(jitclassimpl\u001b[38;5;241m.\u001b[39mclass_impl_registry)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# load 3rd party extensions\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[43mnumba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241m.\u001b[39mentrypoints\u001b[38;5;241m.\u001b[39minit_all()\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# fix for #8940\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munsafe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ndarray\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numba' has no attribute 'core'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Load Wav2Vec2 Model and Processor\n",
    "# -------------------------------------------------------------------\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def speech_to_text(audio_path):\n",
    "    \"\"\"\n",
    "    Loads a WAV file at 16 kHz using librosa,\n",
    "    then transcribes it using the Wav2Vec2 model.\n",
    "    \"\"\"\n",
    "    # Load audio at 16 kHz\n",
    "    speech_array, sampling_rate = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "    # Preprocess audio\n",
    "    inputs = processor(speech_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "    input_values = inputs.input_values.to(device)\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Decode predicted tokens\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "    return transcription\n",
    "\n",
    "def batch_transcribe_wav_files(input_folder, output_file):\n",
    "    \"\"\"\n",
    "    Iterates over all .wav files in `input_folder`,\n",
    "    transcribes them, and saves each result to `output_file`.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for file_name in os.listdir(input_folder):\n",
    "            if file_name.lower().endswith('.wav'):\n",
    "                wav_path = os.path.join(input_folder, file_name)\n",
    "                print(f\"[INFO] Transcribing: {wav_path}\")\n",
    "\n",
    "                transcript = speech_to_text(wav_path)\n",
    "                f.write(f\"{file_name}: {transcript}\\n\")\n",
    "\n",
    "    print(f\"\\n[INFO] Finished transcribing all WAV files.\")\n",
    "    print(f\"[INFO] Results have been saved to: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path where your WAV files are stored\n",
    "    input_folder = r\"C:\\Users\\DELL\\Desktop\\VOIP_Phishing_Attacks\\Repos\\SpeechText\\speech-text-conversion\\assets\\AudioData\\JK\"\n",
    "    \n",
    "    # The file where transcriptions will be written\n",
    "    output_file = \"transcriptions.txt\"\n",
    "    \n",
    "    # Perform batch transcription\n",
    "    batch_transcribe_wav_files(input_folder, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Speech-to-text with Wav2Vec2\n",
    "# -------------------------------------------------------------------\n",
    "# Load the pretrained model and processor once\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "\n",
    "def speech_to_text(audio_path):\n",
    "    \"\"\"\n",
    "    Loads a WAV file (or other supported audio format) at 16 kHz,\n",
    "    then transcribes it using a Wav2Vec2 model.\n",
    "    \"\"\"\n",
    "    # Load the audio at 16 kHz\n",
    "    speech_array, _ = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "    # Preprocess the raw waveform\n",
    "    input_values = processor(\n",
    "        speech_array, \n",
    "        sampling_rate=16000, \n",
    "        return_tensors=\"pt\"\n",
    "    ).input_values\n",
    "\n",
    "    # Inference (no gradient needed)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Argmax to get predicted token IDs\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    # Decode to text\n",
    "    transcription = processor.batch_decode(predicted_ids)[0]\n",
    "    return transcription\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Batch Transcription Function\n",
    "# -------------------------------------------------------------------\n",
    "def batch_transcribe_wav_files(input_folder, output_file):\n",
    "    \"\"\"\n",
    "    Searches for all .wav files in `input_folder`, transcribes each file,\n",
    "    and writes the results to `output_file`.\n",
    "    \n",
    "    Each line in the output file will have the format:\n",
    "        filename: transcription\n",
    "    \"\"\"\n",
    "    # Create or overwrite the output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        # Iterate through everything in the folder\n",
    "        for file_name in os.listdir(input_folder):\n",
    "            if file_name.lower().endswith(\".wav\"):\n",
    "                wav_path = os.path.join(input_folder, file_name)\n",
    "                print(f\"[INFO] Transcribing: {wav_path}\")\n",
    "\n",
    "                # Perform speech-to-text\n",
    "                transcript = speech_to_text(wav_path)\n",
    "\n",
    "                # Write to the .txt file in a simple \"filename: transcript\" format\n",
    "                f.write(f\"{file_name}: {transcript}\\n\")\n",
    "        print(f\"[INFO] Finished batch transcription. Results saved to {output_file}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Example Usage (Uncomment to run)\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Folder containing WAV files\n",
    "    input_folder = r\"C:\\Users\\DELL\\Desktop\\VOIP_Phishing_Attacks\\Repos\\SpeechText\\speech-text-conversion\\assets\\AudioData\\JK\"\n",
    "    \n",
    "    # Where to save the transcriptions\n",
    "    output_file = \"transcriptions.txt\"\n",
    "    \n",
    "    # Call the batch transcription function\n",
    "    batch_transcribe_wav_files(input_folder, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
